{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical approaches before deep learning\n",
    "\n",
    "## Spatial Pyramid Matching (SPM)\n",
    "\n",
    "### Original SPM paper\n",
    "\n",
    "S. Lazebnik, C. Schmid, and J. Ponce, “Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories,” presented at the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06), 2006, vol. 2, pp. 2169–2178.\n",
    "\n",
    "Application of Pyramid kernel (**K. Grauman and T. Darrell, “The pyramid match kernel: discriminative classification with sets of image features”**) in classification.\n",
    "\n",
    "below eq. 4: This approach has the advantage of maintaining continuity with the popular “visual vocabulary” paradigm.\n",
    "\n",
    "This is indeed very important, as in the original pyramid matching, the spatial information is lost (consider using SIFT, the locations are unused, instead, the values in the SIFT feature vectors are used). Here, spatial locations are compared. So in this paper, the features are 2D. In the original pyramid matching paper, features are in 128D (if SIFT has 128 dimensions).\n",
    "\n",
    "end of section 3: here, a different normalization technique is used. Again, this still results in valid kernel, as in the orignial pyramid kernel paper.\n",
    "\n",
    "Some other notes\n",
    "\n",
    "* p.2169: Our own experiments confirm that global representations can be surprisingly effective not only for identifying the overall scene, but also for categorizing images as containing specific objects, even when these objects are embedded in heavy clutter and vary significantly in pose and appearance. -- Highlighted Feb 15, 2017\n",
    "* p.2169: Instead, we envision a subordinate role for this method. It may be used to capture the “gist” of an image [21] and to inform the subsequent -- Highlighted Feb 15, 2017\n",
    "* p.2170: search for specific objects (e.g., if the image, based on its global description, is likely to be a highway, we have a high probability of finding a car, but not a toaster). -- Highlighted Feb 15, 2017\n",
    "* p.2170: empirical success of “subdivide and disorder” techniques is the fact that they actually perform approximate geometric matching. -- Highlighted Feb 15, 2017\n",
    "* p.2170: Koenderink and Van Doorn have argued persuasively that locally orderless images play an important role in visual perception. -- Highlighted Feb 15, 2017\n",
    "* p.2170: suggest that “locally orderless matching” may be a powerful mechanism for estimating overall perceptual similarity between images. -- Highlighted Feb 15, 2017\n",
    "* p.2170: This results in a higher-dimensional representation that preserves more information (e.g., an image consisting of thin black and white stripes would retain two modes at every level of a spatial pyramid, whereas it would become indistinguishable from a uniformly gray image at all but the finest levels of a multiresolution histogram). -- Highlighted Feb 15, 2017\n",
    "* p.2171:  It allows for precise matching of two collections of features in a highdimensional appearance space, but discards all spatial information. -- Highlighted Feb 15, 2017\n",
    "* p.2171: Specifically, we quantize all feature vectors into M discrete types, and make the simplifying assumption that only features of the same type can be matched to one another. -- Highlighted Feb 15, 2017\n",
    "* p.2171: Because we use a dense feature representation (see Section 4), and thus do not need to worry about spurious feature detections resulting from clutter, this practice is sufficient to deal with the effects of variable image size. -- Highlighted Feb 15, 2017\n",
    "* p.2171: The final kernel is then the sum of the separate channel kernels -- Highlighted Feb 15, 2017\n",
    "* p.2171: This approach has the advantage of maintaining continuity with the popular “visual vocabulary” paradigm  -- Highlighted Feb 15, 2017\n",
    "* p.2171: in fact, it reduces to a standard bag of features when L = 0 -- Highlighted Feb 15, 2017\n",
    "\n",
    "~~~\n",
    "@inproceedings{Lazebnik:2006do,\n",
    "author = {Lazebnik, S and Schmid, C and Ponce, J},\n",
    "title = {{Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories}},\n",
    "booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n",
    "year = {2006},\n",
    "pages = {2169--2178},\n",
    "publisher = {IEEE},\n",
    "annote = {Application of Pyramid kernel in classification.\n",
    "\n",
    "below eq. 4: This approach has the advantage of maintaining continuity with the popular {\\textquotedblleft}visual vocabulary{\\textquotedblright} paradigm.\n",
    "\n",
    "This is indeed very important, as in the original pyramid matching, the spatial information is lost (consider using SIFT, the locations are unused, instead, the values in the SIFT feature vectors are used). Here, spatial locations are compared. So in this paper, the features are 2D. In the original pyramid matching paper, features are in 128D (if SIFT has 128 dimensions).\n",
    "\n",
    "end of section 3: here, a different normalization technique is used. Again, this still results in valid kernel, as in the orignial pyramid kernel paper.},\n",
    "keywords = {classics},\n",
    "doi = {10.1109/CVPR.2006.68},\n",
    "isbn = {0-7695-2597-0},\n",
    "read = {Yes},\n",
    "rating = {3},\n",
    "date-added = {2017-02-15T04:28:58GMT},\n",
    "date-modified = {2017-02-17T16:15:52GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/1641019/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2006/Lazebnik/CVPR%202006%202006%20Lazebnik.pdf},\n",
    "file = {{CVPR 2006 2006 Lazebnik.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2006/Lazebnik/CVPR 2006 2006 Lazebnik.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/CVPR.2006.68}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "### changing Vector Quantization to Sparse Coding\n",
    "\n",
    "Jianchao Yang, K. Yu, Yihong Gong, and T. S. Huang, “Linear spatial pyramid matching using sparse coding for image classification,” presented at the 2009 IEEE Conference on Computer Vision and Pattern Recognition, 2009, pp. 1794–1801.\n",
    "\n",
    "Two improvements over traditional spatial pyramid.\n",
    "\n",
    "1. sparse coding dictionary instead of kmeans (vector quantization). This idea is pretty natural, because in 2008, some people pointed out that VQ is not very suitable for SIFT features. See (**O. Boiman, E. Shechtman and M. Irani, \"In defense of Nearest-Neighbor based image classification,\" 2008 IEEE Conference on Computer Vision and Pattern Recognition, Anchorage, AK, 2008, pp. 1-8. doi: 10.1109/CVPR.2008.4587598**). In 2008, Boiman's KNN method is better than VQ-based SPM methods. However, by using sparse coding, KNN get beaten again.\n",
    "2. use max pooling instead of histogram, plus linear kernel, which gives big boosting.\n",
    "\n",
    "In Eq. (7), I think last term should be $M_j$, not $2M$. Check <http://web.eecs.umich.edu/~silvio/teaching/EECS598_2010/slides/10_12_Byung-soo.pdf>.\n",
    "\n",
    "\n",
    "~~~\n",
    "@inproceedings{Yang:2009kg,\n",
    "author = {Jianchao Yang and Yu, Kai and Yihong Gong and Huang, Thomas S},\n",
    "title = {{Linear spatial pyramid matching using sparse coding for image classification}},\n",
    "booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},\n",
    "year = {2009},\n",
    "pages = {1794--1801},\n",
    "publisher = {IEEE},\n",
    "annote = {Two improvements over traditional spatial pyramid.\n",
    "\n",
    "1. sparse coding dictionary instead of kmeans (vector quantization). This idea is pretty natural, because in 2008, some people pointed out that VQ is not very suitable for SIFT features. See (**O. Boiman, E. Shechtman and M. Irani, \"In defense of Nearest-Neighbor based image classification,\" 2008 IEEE Conference on Computer Vision and Pattern Recognition, Anchorage, AK, 2008, pp. 1-8. doi: 10.1109/CVPR.2008.4587598**). In 2008, Boiman's KNN method is better than VQ-based SPM methods. However, by using sparse coding, KNN get beaten again.\n",
    "\n",
    "2. use max pooling instead of histogram, plus linear kernel, which gives big boosting.\n",
    "\n",
    "In Eq. (7), I think last term should be $M_j$, not $2M$. Check <http://web.eecs.umich.edu/{\\textasciitilde}silvio/teaching/EECS598_2010/slides/10_12_Byung-soo.pdf>.},\n",
    "keywords = {sparse coding},\n",
    "doi = {10.1109/CVPR.2009.5206757},\n",
    "isbn = {978-1-4244-3992-8},\n",
    "read = {Yes},\n",
    "rating = {3},\n",
    "date-added = {2017-02-15T20:38:05GMT},\n",
    "date-modified = {2017-02-17T19:32:21GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/5206757/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2009/Jianchao%20Yang/CVPR%202009%202009%20Jianchao%20Yang.pdf},\n",
    "file = {{CVPR 2009 2009 Jianchao Yang.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2009/Jianchao Yang/CVPR 2009 2009 Jianchao Yang.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/CVPR.2009.5206757}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "### changing Sparse Coding to Locality-constrained Linear Coding\n",
    "\n",
    "J. Wang, J. Yang, K. Yu, F. Lv, T. S. Huang, and Y. Gong, “Locality-constrained Linear Coding for image classification,” presented at the 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010, pp. 3360–3367.\n",
    "\n",
    "Further extension of spatial pyramid matching.\n",
    "\n",
    "I think idea of locality is great. Should compare it against sparse coding.\n",
    "\n",
    "Notice that LLC is different from LCC. LCC is a more fancy version of LLC, in a NIPS paper (citation [24] here).\n",
    "\n",
    "In introduction, they mention some works on other extensions of BoF. Probably too fancy to be useful in practice.\n",
    "\n",
    "Other notes\n",
    "\n",
    "* p.3360: Of the many extensions of the BoF method, including the generative part models [7, 3, 2], geometric correspondence search [1, 14] and discriminative codebook learning [13, 17, 23], -- Highlighted Feb 15, 2017\n",
    "* p.3362: As shown in Fig. 2.b, due to the over-completeness of the codebook, the SC process might select quite different bases for similar patches to favor sparsity, thus losing correlations between codes. On the other side, the explicit locality adaptor in LLC ensures that similar patches will have similar codes. -- Highlighted Feb 17, 2017\n",
    "\n",
    "~~~\n",
    "@inproceedings{Wang:2010kx,\n",
    "author = {Wang, Jinjun and Yang, Jianchao and Yu, Kai and Lv, Fengjun and Huang, Thomas S and Gong, Yihong},\n",
    "title = {{Locality-constrained Linear Coding for image classification}},\n",
    "booktitle = {2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
    "year = {2010},\n",
    "pages = {3360--3367},\n",
    "publisher = {IEEE},\n",
    "annote = {Further extension of spatial pyramid matching.\n",
    "\n",
    "I think idea of locality is great. Should compare it against sparse coding.\n",
    "\n",
    "\n",
    "Notice that LLC is different from LCC. LCC is a more fancy version of LLC, in a NIPS paper (citation [24] here).\n",
    "\n",
    "\n",
    "In introduction, they mention some works on other extensions of BoF. Probably too fancy to be useful in practice.\n",
    "},\n",
    "keywords = {sparse coding},\n",
    "doi = {10.1109/CVPR.2010.5540018},\n",
    "isbn = {978-1-4244-6984-0},\n",
    "read = {Yes},\n",
    "rating = {4},\n",
    "date-added = {2017-02-15T20:44:07GMT},\n",
    "date-modified = {2017-02-17T19:33:31GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/5540018/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2010/Wang/CVPR%202010%202010%20Wang.pdf},\n",
    "file = {{CVPR 2010 2010 Wang.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2010/Wang/CVPR 2010 2010 Wang.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/CVPR.2010.5540018}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "### Super Vector\n",
    "\n",
    "X. Zhou, K. Yu, T. Zhang, and T. S. Huang, “Image Classification Using Super-Vector Coding of Local Image Descriptors,” presented at the Computer Vision - ECCV 2010 - 11th European Conference on Computer Vision, Heraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part V, 2010, vol. 6315, pp. 141–154.\n",
    "\n",
    "This is different from all other previous methods, is that the dimension of the encoding is related to the dimension of the original SIFT descriptor.\n",
    "\n",
    "The motivation of SV using approximating function is great.\n",
    "\n",
    "In (2), the reason that we need constant $s$ is probably because feature vectors (after kernel trick) are normalized, so SVM may not be able to perform the same with different $s$. See 1.1 of the paper:\n",
    "\n",
    "> 3\\. Image classification:\n",
    "The image-level feature vector is normalized and fed into a classifier. We choose linear SVMs, which scale linearly to the size of training data.\n",
    "\n",
    "In pp. 146, spatial pyramid pooling uses 8 blocks, 1x1, 2x2, and 3x1. This is probably heuristically the best. As seen in the Fisher Kernel paper, or the Devils in the details paper.\n",
    "\n",
    "In pp. 147, Eq. (5) shows that we can somehow decompose the score of SVM by the summation of different descriptors (well here no spatial pyramid is used, I  guess for visualization, the w corresponding to the 1x1 block is used). We can visualize the classifier as using each descriptor's score and location, as in Fig. 3.\n",
    "\n",
    "In pp. 148, the second equation should be wrong, as it can't be reduced to second equation in pp. 146. But anyway, it should be easy to derive.\n",
    "\n",
    "In pp. 148, they talk about difference of Super Vector and Fisher Vector (Fisher kernel) (I mean citation [21], not sure about [22]). Based on the Fisher Vector paper below, seems that Fisher Vector first model descriptor as GMM, and then use some \"distribution kernels\" for distance metric. Here, some distribution kernel is still used, but it's modulated by a term ($\\kappa(x,x')$ in pp. 145). Seems that SV is more nonparameteric than FV. Also SV is good in that it's just slight modification to VQ, which is popular.\n",
    "\n",
    "~~~\n",
    "@inproceedings{Zhou:2010da,\n",
    "author = {Zhou, Xi and Yu, Kai and Zhang, Tong and Huang, Thomas S},\n",
    "title = {{Image Classification Using Super-Vector Coding of Local Image Descriptors}},\n",
    "booktitle = {Computer Vision - ECCV 2010 - 11th European Conference on Computer Vision, Heraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part V},\n",
    "year = {2010},\n",
    "editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},\n",
    "pages = {141--154},\n",
    "publisher = {Springer},\n",
    "annote = {This is different from all other previous methods, is that the dimension of the encoding is related to the dimension of the original SIFT descriptor.\n",
    "\n",
    "The motivation of SV using approximating function is great.\n",
    "\n",
    "In (2), the reason that we need constant s is probably because feature vectors (after kernel trick) are normalized, so SVM may not be able to perform the same with different s. See 1.1 of the paper:\n",
    "\n",
    "> 3 Image classification:\n",
    "The image-level feature vector is normalized and fed into a classifier. We choose linear SVMs, which scale linearly to the size of training data.\n",
    "\n",
    "In pp. 146, spatial pyramid pooling uses 8 blocks, 1x1, 2x2, and 3x1. This is probably heuristically the best. As seen in the Fisher Kernel paper, or the Devils in the details paper.\n",
    "\n",
    "In pp. 147, Eq. (5) shows that we can somehow decompose the score of SVM by the summation of different descriptors (well here no spatial pyramid is used, I  guess for visualization, the w corresponding to the 1x1 block is used). We can visualize the classifier as using each descriptor's score and location, as in Fig. 3.\n",
    "\n",
    "In pp. 148, the second equation should be wrong, as it can't be reduced to second equation in pp. 146. But anyway, it should be easy to derive.\n",
    "\n",
    "In pp. 148, they talk about difference of Super Vector and Fisher Vector (Fisher kernel) (I mean citation [21], not sure about [22]). Based on the Fisher Vector paper below, seems that Fisher Vector first model descriptor as GMM, and then use some \"distribution kernels\" for distance metric. Here, some distribution kernel is still used, but it's modulated by a term ($\\kappa(x,x')$ in pp. 145). Seems that SV is more nonparameteric than FV. Also SV is good in that it's just slight modification to VQ, which is popular.\n",
    "\n",
    "\n",
    "\n",
    "},\n",
    "doi = {10.1007/978-3-642-15555-0_11},\n",
    "language = {English},\n",
    "read = {Yes},\n",
    "rating = {3},\n",
    "date-added = {2017-02-16T20:01:04GMT},\n",
    "date-modified = {2017-02-17T19:31:32GMT},\n",
    "abstract = {This paper introduces a new framework for image classification using local visual descriptors. The pipeline first performs a nonlinear feature transformation on descriptors, then aggregates the result},\n",
    "url = {http://dx.doi.org/10.1007/978-3-642-15555-0_11},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2010/Zhou/ECCV%202010%20Part%20V%202010%20Zhou.pdf},\n",
    "file = {{ECCV 2010 Part V 2010 Zhou.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2010/Zhou/ECCV 2010 Part V 2010 Zhou.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1007/978-3-642-15555-0_11}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "### Fisher Vector\n",
    "\n",
    "F. Perronnin, J. Sánchez, and T. Mensink, “Improving the Fisher Kernel for Large-Scale Image Classification,” presented at the Computer Vision - ECCV 2010, 11th European Conference on Computer Vision, Heraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part IV, 2010, vol. 6314, pp. 143–156.\n",
    "\n",
    "I like the idea of looking into feature vector and think about why it fails. This is the reason two improvements can be made here. This is important for all types of research.\n",
    "\n",
    "the power normalization (using $\\alpha=0.5$) is also called Hellinger's kernel. See <http://www.vlfeat.org/api/fisher-fundamentals.html#fisher-normalization> or the description of (improved) fisher kernel in [Return of Devils paper](http://www.robots.ox.ac.uk/~vgg/research/deep_eval/).\n",
    "\n",
    "other notes\n",
    "\n",
    "* p.144: We stress that all the methods mentioned previously are inherently limited by the shortcomings of the BOV representation, and especially by the fact that the descriptor quantization is a lossy process as underlined in the work of Boiman et al. [19]. -- Highlighted Feb 17, 2017\n",
    "* p.144: Therefore the FK overcomes some of the limitations raised by [19]. Yet, in practice, the FK has led to somewhat disappointing results – no better than the BOV. -- Highlighted Feb 17, 2017\n",
    "\n",
    "~~~\n",
    "@inproceedings{Perronnin:2010hg,\n",
    "author = {Perronnin, Florent and S{\\'a}nchez, Jorge and Mensink, Thomas},\n",
    "title = {{Improving the Fisher Kernel for Large-Scale Image Classification}},\n",
    "booktitle = {Computer Vision - ECCV 2010, 11th European Conference on Computer Vision, Heraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part IV},\n",
    "year = {2010},\n",
    "editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},\n",
    "pages = {143--156},\n",
    "publisher = {Springer},\n",
    "annote = {I like the idea of looking into feature vector and think about why it fails. This is the reason two improvements can be made here. This is important for all types of research.},\n",
    "doi = {10.1007/978-3-642-15561-1_11},\n",
    "language = {English},\n",
    "read = {Yes},\n",
    "rating = {4},\n",
    "date-added = {2017-02-16T20:13:49GMT},\n",
    "date-modified = {2017-02-17T19:36:32GMT},\n",
    "abstract = {The Fisher kernel (FK) is a generic framework which combines the benefits of generative and discriminative approaches. In the context of image classification the FK was shown to extend the popular bag},\n",
    "url = {http://dx.doi.org/10.1007/978-3-642-15561-1_11},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2010/Perronnin/2010%20Perronnin.pdf},\n",
    "file = {{2010 Perronnin.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2010/Perronnin/2010 Perronnin.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1007/978-3-642-15561-1_11}}\n",
    "}\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
