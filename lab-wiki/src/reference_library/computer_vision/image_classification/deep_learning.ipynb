{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## early attempts at MNIST/CIFAR era\n",
    "\n",
    "D. Ciresan, U. Meier, and J. Schmidhuber, “Multi-column deep neural networks for image classification,” presented at the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012, pp. 3642–3649.\n",
    "\n",
    "Notes: good old paper for deep CNN.\n",
    "\n",
    "See Figure 1.\n",
    "\n",
    "I think Fig1(b) makes sense intuitively. \n",
    "\n",
    "Maybe later on, people find that multiple paths are kind of useless.\n",
    "\n",
    "~~~\n",
    "@inproceedings{Ciresan:2012gw,\n",
    "author = {Ciresan, D and Meier, U and Schmidhuber, J},\n",
    "title = {{Multi-column deep neural networks for image classification}},\n",
    "booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
    "year = {2012},\n",
    "pages = {3642--3649},\n",
    "publisher = {IEEE},\n",
    "annote = {good old paper for deep CNN.\n",
    "\n",
    "See Figure 1.\n",
    "\n",
    "I think Fig1(b) makes sense intuitively. \n",
    "\n",
    "Maybe later on, people find that multiple paths are kind of useless.},\n",
    "keywords = {deep learning, ensemble},\n",
    "doi = {10.1109/CVPR.2012.6248110},\n",
    "isbn = {978-1-4673-1226-4},\n",
    "read = {Yes},\n",
    "rating = {4},\n",
    "date-added = {2017-05-05T21:02:19GMT},\n",
    "date-modified = {2017-05-05T21:07:20GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/6248110/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2012/Ciresan/CVPR%202012%202012%20Ciresan.pdf},\n",
    "file = {{CVPR 2012 2012 Ciresan.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2012/Ciresan/CVPR 2012 2012 Ciresan.pdf:application/pdf;CVPR 2012 2012 Ciresan.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2012/Ciresan/CVPR 2012 2012 Ciresan.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/CVPR.2012.6248110}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "\n",
    "## GoogLeNet\n",
    "\n",
    "C. Szegedy, Wei Liu, Yangqing Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” presented at the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 1–9.\n",
    "\n",
    "Notes: Power of deep architecture + multi scale filters.\n",
    "\n",
    "Notice that one disadvantage of multi scale is that, for dealing with alignment of different filters, stride=1 needs to be used. This creates computation burden. That's why we don't see inception module in the first layer.\n",
    "\n",
    "Throughout the paper, they say some designs are guided by [2] \"Provable bounds for learning some deep representations\". I would say this is loose application of that paper. Most importantly, that paper is only talking about generative model, and CNN is doing inference. Sparse connectivity in generative model doesn't mean sparse in inference, due to explaining away, etc. See hinton's neural network course for difficulty of inference in belief net models.\n",
    "\n",
    "\n",
    "~~~\n",
    "@inproceedings{Szegedy:2015gt,\n",
    "author = {Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},\n",
    "title = {{Going deeper with convolutions}},\n",
    "booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
    "year = {2015},\n",
    "pages = {1--9},\n",
    "publisher = {IEEE},\n",
    "annote = {Power of deep architecture + multi scale filters.\n",
    "\n",
    "Notice that one disadvantage of multi scale is that, for dealing with alignment of different filters, stride=1 needs to be used. This creates computation burden. That's why we don't see inception module in the first layer.\n",
    "\n",
    "Throughout the paper, they say some designs are guided by [2] \"Provable bounds for learning some deep representations\". I would say this is loose application of that paper. Most importantly, that paper is only talking about generative model, and CNN is doing inference. Sparse connectivity in generative model doesn't mean sparse in inference, due to explaining away, etc. See hinton's neural network course for difficulty of inference in belief net models.},\n",
    "keywords = {deep learning},\n",
    "doi = {10.1109/CVPR.2015.7298594},\n",
    "isbn = {978-1-4673-6964-0},\n",
    "read = {Yes},\n",
    "rating = {4},\n",
    "date-added = {2017-02-28T18:29:44GMT},\n",
    "date-modified = {2017-03-27T01:03:44GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/7298594/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2015/Szegedy/CVPR%202015%202015%20Szegedy.pdf},\n",
    "file = {{CVPR 2015 2015 Szegedy.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2015/Szegedy/CVPR 2015 2015 Szegedy.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/CVPR.2015.7298594}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "## VGG\n",
    "\n",
    "K. Simonyan and A. Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition,” arXiv, vol. cs.CV, Sep. 2014.\n",
    "\n",
    "Notes: another example in the line of Network in Network (1x1 convolution) and GoogleNet (deep).\n",
    "\n",
    "Not having bell and whistles of GoogleNet, actually better performance.\n",
    "\n",
    "\n",
    "~~~\n",
    "@article{Simonyan:2014ws,\n",
    "author = {Simonyan, K and Zisserman, Andrew},\n",
    "title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},\n",
    "journal = {ArXiv e-prints},\n",
    "year = {2014},\n",
    "volume = {cs.CV},\n",
    "month = sep,\n",
    "annote = {another example in the line of Network in Network (1x1 convolution) and GoogleNet (deep).\n",
    "\n",
    "Not having bell and whistles of GoogleNet, actually better performance.},\n",
    "keywords = {classics, deep learning},\n",
    "read = {Yes},\n",
    "rating = {4},\n",
    "date-added = {2017-02-28T18:42:08GMT},\n",
    "date-modified = {2017-03-27T01:05:54GMT},\n",
    "url = {http://arxiv.org/abs/1409.1556},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2014/Simonyan/arXiv%202014%20Simonyan.pdf},\n",
    "file = {{arXiv 2014 Simonyan.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2014/Simonyan/arXiv 2014 Simonyan.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/uuid/37E26287-E842-4F5C-B224-1CF59CA4D568}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "## Recurrent CNN\n",
    "\n",
    "Ming Liang and Xiaolin Hu, “Recurrent convolutional neural network for object recognition,” presented at the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3367–3375.\n",
    "\n",
    "Notes: Essentially, parameter sharing and skip connection in CNN layers. Check Fig 3\n",
    "\n",
    "Not sure why this work is not popular. Biggest reason might be 1) having no code; 2) not tested on ImageNet.\n",
    "\n",
    "\n",
    "~~~\n",
    "@inproceedings{MingLiang:2015cm,\n",
    "author = {Ming Liang and Xiaolin Hu},\n",
    "title = {{Recurrent convolutional neural network for object recognition}},\n",
    "booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
    "year = {2015},\n",
    "pages = {3367--3375},\n",
    "publisher = {IEEE},\n",
    "annote = {Essentially, parameter sharing and skip connection in CNN layers. Check Fig 3\n",
    "\n",
    "Not sure why this work is not popular. Biggest reason might be 1) having no code; 2) not tested on ImageNet.},\n",
    "keywords = {deep learning, recurrent},\n",
    "doi = {10.1109/CVPR.2015.7298958},\n",
    "isbn = {978-1-4673-6964-0},\n",
    "read = {Yes},\n",
    "rating = {3},\n",
    "date-added = {2017-02-24T22:38:22GMT},\n",
    "date-modified = {2017-03-27T01:06:38GMT},\n",
    "url = {http://ieeexplore.ieee.org/document/7298958/},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2015/Ming%20Liang/CVPR%202015%202015%20Ming%20Liang.pdf},\n",
    "file = {{CVPR 2015 2015 Ming Liang.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2015/Ming Liang/CVPR 2015 2015 Ming Liang.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/doi/10.1109/CVPR.2015.7298958}}\n",
    "}\n",
    "~~~\n",
    "\n",
    "## ResNet\n",
    "\n",
    "[1]\tK. He, S. Ren, J. Sun, and X. Zhang, “Deep Residual Learning for Image Recognition,” arXiv, vol. cs.CV, Dec. 2015.\n",
    "\n",
    "Notes: resnet is a classical example, making network easier to train, rather than finding better optimization methods.\n",
    "\n",
    "Spiritually, it's similar to batch normalization. The key to performance improvement is not having more parameters, or allowing more types of functions to be learned (at least not the focus), but having better learning dynamics.\n",
    "\n",
    "When there's mismatch in number of units across layers, a general 1x1 convolution, rather than pointwise addition, is used to match dimensions.\n",
    "\n",
    "Please check identity mapping paper [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) for better residual net blocks, if you really want to go deep.\n",
    "\n",
    "other notes\n",
    "\n",
    "* p.1: The degradation (of training accuracy) indicates that not all systems are similarly easy to optimize. -- Highlighted Mar 27, 2017\n",
    "* p.1-2: But experiments show that our current solvers on hand are unable to find solutions that are comparably good or better than the constructed solution (or unable to do so in feasible time). -- Highlighted Mar 27, 2017\n",
    "\n",
    "~~~\n",
    "@article{He:2015tt,\n",
    "author = {He, Kaiming and Ren, Shaoqing and Sun, Jian and Zhang, Xiangyu},\n",
    "title = {{Deep Residual Learning for Image Recognition}},\n",
    "journal = {ArXiv e-prints},\n",
    "year = {2015},\n",
    "volume = {cs.CV},\n",
    "month = dec,\n",
    "annote = {resnet is a classical example, making network easier to train, rather than finding better optimization methods.\n",
    "\n",
    "Spiritually, it's similar to batch normalization. The key to performance improvement is not having more parameters, or allowing more types of functions to be learned (at least not the focus), but having better learning dynamics.\n",
    "\n",
    "When there's mismatch in number of units across layers, a general 1x1 convolution, rather than pointwise addition, is used to match dimensions.\n",
    "\n",
    "Please check identity mapping paper [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) for better residual net blocks, if you really want to go deep.},\n",
    "keywords = {classics, deep learning},\n",
    "read = {Yes},\n",
    "rating = {5},\n",
    "date-added = {2017-02-28T18:22:36GMT},\n",
    "date-modified = {2017-03-27T20:01:33GMT},\n",
    "url = {http://arxiv.org/abs/1512.03385},\n",
    "local-url = {file://localhost/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2015/He/arXiv%202015%20He.pdf},\n",
    "file = {{arXiv 2015 He.pdf:/Users/yimengzh/Documents/Papers3_revised/Library.papers3/Articles/2015/He/arXiv 2015 He.pdf:application/pdf}},\n",
    "uri = {\\url{papers3://publication/uuid/F8608028-F58E-4705-A893-0E485C161AF1}}\n",
    "}\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
